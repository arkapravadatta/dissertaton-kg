{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a761df9",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b431394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns detected: ['Employee_Name', 'EmpID', 'MarriedID', 'MaritalStatusID', 'GenderID', 'EmpStatusID', 'DeptID', 'PerfScoreID', 'FromDiversityJobFairID', 'Salary', 'Termd', 'PositionID', 'Position', 'State', 'Zip', 'DOB', 'Sex', 'MaritalDesc', 'CitizenDesc', 'HispanicLatino', 'RaceDesc', 'DateofHire', 'DateofTermination', 'TermReason', 'EmploymentStatus', 'Department', 'ManagerName', 'ManagerID', 'RecruitmentSource', 'PerformanceScore', 'EngagementSurvey', 'EmpSatisfaction', 'SpecialProjectsCount', 'LastPerformanceReview_Date', 'DaysLateLast30', 'Absences']\n",
      "NO Columns detected: 36\n",
      "Total rows: 311\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSV safely\n",
    "df = pd.read_csv(\"HRDataset_v14.csv\", encoding=\"utf-8\")\n",
    "\n",
    "print(\"Columns detected:\", list(df.columns))\n",
    "print(\"NO Columns detected:\", len(df.columns))\n",
    "print(\"Total rows:\", len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632e837d",
   "metadata": {},
   "source": [
    "csv to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec3aed62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample document:\n",
      "Employee_Name: Adinolfi, Wilson  K | EmpID: 10026 | MarriedID: 0 | MaritalStatusID: 0 | GenderID: 1 | EmpStatusID: 1 | DeptID: 5 | PerfScoreID: 4 | FromDiversityJobFairID: 0 | Salary: 62506 | Termd: 0 | PositionID: 19 | Position: Production Technician I | State: MA | Zip: 1960 | DOB: 07/10/83 | Sex: M  | MaritalDesc: Single | CitizenDesc: US Citizen | HispanicLatino: No | RaceDesc: White | DateofHire: 7/5/2011 | TermReason: N/A-StillEmployed | EmploymentStatus: Active | Department: Production        | ManagerName: Michael Albert | ManagerID: 22.0 | RecruitmentSource: LinkedIn | PerformanceScore: Exceeds | EngagementSurvey: 4.6 | EmpSatisfaction: 5 | SpecialProjectsCount: 0 | LastPerformanceReview_Date: 1/17/2019 | DaysLateLast30: 0 | Absences: 1\n"
     ]
    }
   ],
   "source": [
    "def row_to_text(row):\n",
    "    parts = []\n",
    "    for col, val in row.items():\n",
    "        if pd.notna(val):\n",
    "            parts.append(f\"{col}: {val}\")\n",
    "    return \" | \".join(parts)\n",
    "\n",
    "documents = [row_to_text(row) for _, row in df.iterrows()]\n",
    "\n",
    "print(\"Sample document:\")\n",
    "print(documents[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec476c4",
   "metadata": {},
   "source": [
    "Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f51a03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents created: 311\n",
      "\n",
      "Sample Document Content:\n",
      "Employee_Name: Adinolfi, Wilson  K | EmpID: 10026 | MarriedID: 0 | MaritalStatusID: 0 | GenderID: 1 | EmpStatusID: 1 | DeptID: 5 | PerfScoreID: 4 | FromDiversityJobFairID: 0 | Salary: 62506 | Termd: 0 | PositionID: 19 | Position: Production Technician I | State: MA | Zip: 1960 | DOB: 07/10/83 | Sex: M  | MaritalDesc: Single | CitizenDesc: US Citizen | HispanicLatino: No | RaceDesc: White | DateofHire: 7/5/2011 | TermReason: N/A-StillEmployed | EmploymentStatus: Active | Department: Production        | ManagerName: Michael Albert | ManagerID: 22.0 | RecruitmentSource: LinkedIn | PerformanceScore: Exceeds | EngagementSurvey: 4.6 | EmpSatisfaction: 5 | SpecialProjectsCount: 0 | LastPerformanceReview_Date: 1/17/2019 | DaysLateLast30: 0 | Absences: 1\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "# 1. Create LangChain Documents directly from your strings\n",
    "# No RecursiveCharacterTextSplitter needed here because each row is already a discrete \"chunk\"\n",
    "chunks = [Document(page_content=doc) for doc in documents]\n",
    "\n",
    "print(f\"Total documents created: {len(chunks)}\")\n",
    "\n",
    "# 2. Verify the content to ensure DateofHire is intact\n",
    "print(\"\\nSample Document Content:\")\n",
    "print(chunks[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba451974",
   "metadata": {},
   "source": [
    "Embedding chunks to FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3915610e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline FAISS vector store ready (in-memory)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Embedding model (open-source, local)\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# Create in-memory FAISS vector store\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding_model\n",
    ")\n",
    "\n",
    "print(\"Baseline FAISS vector store ready (in-memory)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03ea065",
   "metadata": {},
   "source": [
    "LLM Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9fba5f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ChatGroq LLM initialized successfully\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.environ.get(\"GROQ_API_KEY\")\n",
    "\n",
    "try:\n",
    "    if not groq_api_key:\n",
    "        raise ValueError(\"GROQ_API_KEY not found in environment variables\")\n",
    "\n",
    "    llm = ChatGroq(\n",
    "        groq_api_key=groq_api_key,\n",
    "        model_name=\"llama-3.1-8b-instant\",\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    # Minimal sanity check call\n",
    "    llm.invoke(\"ping\")\n",
    "\n",
    "    print(\"‚úÖ ChatGroq LLM initialized successfully\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"‚ùå ChatGroq LLM initialization failed\")\n",
    "    print(f\"Error: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8e12c4",
   "metadata": {},
   "source": [
    "Retrival "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69e22ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Searching for: 'DOB: 06/14/87'...\n",
      "\n",
      "Retrieved chunks:\n",
      "\n",
      "--- Chunk 1 ---\n",
      "Employee_Name: Le, Binh | EmpID: 10232 | MarriedID: 0 | MaritalStatusID: 0 | GenderID: 0 | EmpStatusID: 1 | DeptID: 3 | PerfScoreID: 3 | FromDiversityJobFairID: 0 | Salary: 81584 | Termd: 0 | PositionID: 22 | Position: Senior BI Developer | State: MA | Zip: 1886 | DOB: 06/14/87 | Sex: F | MaritalDesc: Single | CitizenDesc: US Citizen | HispanicLatino: No | RaceDesc: Asian | DateofHire: 10/2/2016 | TermReason: N/A-StillEmployed | EmploymentStatus: Active | Department: IT/IS | ManagerName: Brian Champaigne | ManagerID: 13.0 | RecruitmentSource: Indeed | PerformanceScore: Fully Meets | EngagementSurvey: 4.1 | EmpSatisfaction: 5 | SpecialProjectsCount: 7 | LastPerformanceReview_Date: 1/8/2019 | DaysLateLast30: 0 | Absences: 2\n",
      "\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Employee_Name: Bernstein, Sean | EmpID: 10046 | MarriedID: 0 | MaritalStatusID: 0 | GenderID: 1 | EmpStatusID: 1 | DeptID: 5 | PerfScoreID: 3 | FromDiversityJobFairID: 0 | Salary: 51044 | Termd: 0 | PositionID: 19 | Position: Production Technician I | State: MA | Zip: 2072 | DOB: 12/22/70 | Sex: M  | MaritalDesc: Single | CitizenDesc: US Citizen | HispanicLatino: Yes | RaceDesc: White | DateofHire: 4/2/2012 | TermReason: N/A-StillEmployed | EmploymentStatus: Active | Department: Production        | ManagerName: Amy Dunn | ManagerID: 11.0 | RecruitmentSource: Google Search | PerformanceScore: Fully Meets | EngagementSurvey: 5.0 | EmpSatisfaction: 3 | SpecialProjectsCount: 0 | LastPerformanceReview_Date: 1/14/2019 | DaysLateLast30: 0 | Absences: 13\n",
      "\n",
      "\n",
      "--- Chunk 3 ---\n",
      "Employee_Name: Smith, Leigh Ann | EmpID: 10153 | MarriedID: 1 | MaritalStatusID: 1 | GenderID: 0 | EmpStatusID: 5 | DeptID: 1 | PerfScoreID: 3 | FromDiversityJobFairID: 1 | Salary: 55000 | Termd: 1 | PositionID: 2 | Position: Administrative Assistant | State: MA | Zip: 1844 | DOB: 06/14/87 | Sex: F | MaritalDesc: Married | CitizenDesc: US Citizen | HispanicLatino: No | RaceDesc: Black or African American | DateofHire: 9/26/2011 | DateofTermination: 9/25/2013 | TermReason: career change | EmploymentStatus: Voluntarily Terminated | Department: Admin Offices | ManagerName: Brandon R. LeBlanc | ManagerID: 1.0 | RecruitmentSource: Diversity Job Fair | PerformanceScore: Fully Meets | EngagementSurvey: 3.8 | EmpSatisfaction: 4 | SpecialProjectsCount: 4 | LastPerformanceReview_Date: 8/15/2013 | DaysLateLast30: 0 | Absences: 17\n",
      "\n",
      "\n",
      "--- Chunk 4 ---\n",
      "Employee_Name: Wang, Charlie | EmpID: 10172 | MarriedID: 0 | MaritalStatusID: 0 | GenderID: 1 | EmpStatusID: 1 | DeptID: 3 | PerfScoreID: 3 | FromDiversityJobFairID: 0 | Salary: 84903 | Termd: 0 | PositionID: 22 | Position: Senior BI Developer | State: MA | Zip: 1887 | DOB: 07/08/81 | Sex: M  | MaritalDesc: Single | CitizenDesc: US Citizen | HispanicLatino: No | RaceDesc: Asian | DateofHire: 2/15/2017 | TermReason: N/A-StillEmployed | EmploymentStatus: Active | Department: IT/IS | ManagerName: Brian Champaigne | ManagerID: 13.0 | RecruitmentSource: Indeed | PerformanceScore: Fully Meets | EngagementSurvey: 3.42 | EmpSatisfaction: 4 | SpecialProjectsCount: 7 | LastPerformanceReview_Date: 1/4/2019 | DaysLateLast30: 0 | Absences: 17\n",
      "\n",
      "\n",
      "--- Chunk 5 ---\n",
      "Employee_Name: Hutter, Rosalie | EmpID: 10214 | MarriedID: 0 | MaritalStatusID: 3 | GenderID: 0 | EmpStatusID: 2 | DeptID: 5 | PerfScoreID: 3 | FromDiversityJobFairID: 0 | Salary: 64995 | Termd: 0 | PositionID: 20 | Position: Production Technician II | State: MA | Zip: 2351 | DOB: 05/07/92 | Sex: F | MaritalDesc: Separated | CitizenDesc: US Citizen | HispanicLatino: No | RaceDesc: White | DateofHire: 6/5/2015 | TermReason: N/A-StillEmployed | EmploymentStatus: Active | Department: Production        | ManagerName: Webster Butler | RecruitmentSource: Indeed | PerformanceScore: Fully Meets | EngagementSurvey: 4.5 | EmpSatisfaction: 3 | SpecialProjectsCount: 0 | LastPerformanceReview_Date: 2/14/2019 | DaysLateLast30: 0 | Absences: 6\n",
      "\n",
      "\n",
      "--- Chunk 6 ---\n",
      "Employee_Name: Bozzi, Charles | EmpID: 10175 | MarriedID: 0 | MaritalStatusID: 0 | GenderID: 1 | EmpStatusID: 5 | DeptID: 5 | PerfScoreID: 3 | FromDiversityJobFairID: 0 | Salary: 74312 | Termd: 1 | PositionID: 18 | Position: Production Manager | State: MA | Zip: 1901 | DOB: 03/10/70 | Sex: M  | MaritalDesc: Single | CitizenDesc: US Citizen | HispanicLatino: No | RaceDesc: Asian | DateofHire: 9/30/2013 | DateofTermination: 8/7/2014 | TermReason: retiring | EmploymentStatus: Voluntarily Terminated | Department: Production        | ManagerName: Janet King | ManagerID: 2.0 | RecruitmentSource: Indeed | PerformanceScore: Fully Meets | EngagementSurvey: 3.39 | EmpSatisfaction: 3 | SpecialProjectsCount: 0 | LastPerformanceReview_Date: 2/20/2014 | DaysLateLast30: 0 | Absences: 14\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_classic.retrievers import EnsembleRetriever\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "# 1. Initialize Vector Retriever (Semantic)\n",
    "vector_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# 2. Initialize BM25 Retriever (Keyword/Exact Match)\n",
    "# We recreate this here to ensure it uses the latest 'chunks'\n",
    "bm25_retriever = BM25Retriever.from_documents(chunks)\n",
    "bm25_retriever.k = 3\n",
    "\n",
    "# 3. Create Ensemble Retriever\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, vector_retriever],\n",
    "    weights=[0.5, 0.5]  # Adjust weights if you want to favor keywords more (e.g., [0.7, 0.3])\n",
    ")\n",
    "\n",
    "# 4. Take query from user input\n",
    "query = input(\"Enter your query for Retrieval: \").strip()\n",
    "\n",
    "if not query:\n",
    "    raise ValueError(\"Query cannot be empty\")\n",
    "\n",
    "print(f\"\\nüîç Searching for: '{query}'...\")\n",
    "\n",
    "# 5. Perform Hybrid Search\n",
    "results = ensemble_retriever.invoke(query)\n",
    "\n",
    "print(\"\\nRetrieved chunks:\\n\")\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"--- Chunk {i} ---\")\n",
    "    print(doc.page_content)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a041be3",
   "metadata": {},
   "source": [
    "LLM QA Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40109062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß† Generating answer for: '5Which recruitment source was used to hire \"Elijiah Gray\"?'...\n",
      "\n",
      "ü§ñ LLM Answer:\n",
      "--------------------------------------------------\n",
      "I don't know. \n",
      "\n",
      "However, I can tell you that Elijiah Gray is a manager in the Production department, but I do not see any information about his own hiring or recruitment source in the provided data.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 1. Take query from user input\n",
    "# (You can remove this input() line if you want to reuse the query from Cell 1)\n",
    "query = input(\"Enter your query for LLM Answer: \").strip()\n",
    "\n",
    "if not query:\n",
    "    raise ValueError(\"Query cannot be empty\")\n",
    "\n",
    "# 2. Retrieve Documents using the Ensemble Retriever from Cell 1\n",
    "# This ensures we get the exact date matches AND the semantic meaning\n",
    "retrieved_docs = ensemble_retriever.invoke(query)\n",
    "\n",
    "# 3. Combine retrieved chunks into a single context string\n",
    "context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "# 4. Create the Prompt Template\n",
    "prompt_template = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a helpful HR assistant. Use the following employee records to answer the question accurately.\n",
    "If the answer is not in the context, strictly state that you don't know.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: \n",
    "{question}\n",
    "\"\"\")\n",
    "\n",
    "# 5. Format the prompt\n",
    "prompt = prompt_template.format_messages(\n",
    "    context=context_text,\n",
    "    question=query\n",
    ")\n",
    "\n",
    "# 6. Generate Response\n",
    "print(f\"\\nüß† Generating answer for: '{query}'...\")\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "print(\"\\nü§ñ LLM Answer:\")\n",
    "print(\"-\" * 50)\n",
    "print(response.content)\n",
    "print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
